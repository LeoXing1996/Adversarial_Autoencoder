Mnist Dense training with y labels and z=5, ==============
Reconstruction loss 17,2 with adam 0.0002
Reconstruction loss 15.77 with adam 0.00004
Reconstruction loss 15.54 with adam 0.000008
-------------------------------------------
0.0002  -> 0.025644
0.00004 -> 0.023410
After RMSProp -> 0.022315



Mnist Dense training without y labels and z=5,=============
Reconstruction loss 25.64 with adam 0.0002
Reconstruction loss 21.64 with adam 0.00004
-------------------------------------------------

0.0002  -> 0.0278
0.00004 -> 0.026297
After RMSProp ->  0.025360
 
Mnist Conv training with y labels and z=5,
Reconstruction loss 23.01 with adam 0.0002
Reconstruction loss 21.48 with adam 0.00004
0.0002  -> 0.027869
0.00004 -> 0.026446
After RMSProp -> 0.027287
------------
FixedBN:
0.0002 -> 0.028565



Subpix noy epoch ============================================
Parameters: 1042810
Reconstruction loss 82.41 with adam 0.0002
Reconstruction loss 78.76 with adam 0.00004
--------------------------------------------
Number of parameters in model 2171994
LR : 0.0002, 0.0002, 0.0002
Starting epoch 40
Epoch took 1235 seconds.
Reconstruction Lost 94.468611
Discrimination Lost 0.693490
Encoder Lost 0.695844
LR : 0.00005, 0.0002, 0.0002
--------------------------------------------
Epoch 15:
0.033366

Celeb Conv noy ==============================================
Parameters: 827690
93.35
--------------------------------------------
Number of parameters in model 826762
LR : 0.0002, 0.0002, 0.0002
Starting epoch 33
Epoch took 1443 seconds.
Reconstruction Lost 102.588236
Discrimination Lost 0.683555
Encoder Lost 0.720770
LR : 0.00005, 0.0002, 0.0002
---------------------------------------------
0.051










Mnist Conv training without y labels and z=5,
Reconstruction loss 27.10 with adam 0.0002
Reconstruction loss 23.05 with adam 0.00004






Celeb Res y 
105.7

Celeb Res noy
85.34

Celeb Conv y ================================================
110.73
-------------------------------------------
LR : 0.0002, 0.0002, 0.0002
Starting epoch 33
Epoch took 1449 seconds.
Reconstruction Lost 139.458588
Discrimination Lost 0.647007
Encoder Lost 0.850248







Celeb Gan Res noy
102.23

Celeb 128
1836.60





We train subpix without gan and we get:

Starting epoch 14
Epoch took 3523 seconds.
Reconstruction Lost 0.033569
Discrimination Lost 0.676666
Encoder Lost 0.736910

Model saved as models/model_Celeb_Subpix_noy_bn.ckpt
Starting epoch 15
Epoch took 3560 seconds.
Reconstruction Lost 0.033366
Discrimination Lost 0.673484
Encoder Lost 0.745762

Model saved as models/model_Celeb_Subpix_noy_bn.ckpt
Starting epoch 16
Epoch took 3409 seconds.
Reconstruction Lost 0.033367
Discrimination Lost 0.669159
Encoder Lost 0.757511


Next we try to see what changes when we put batch norm before relu is applied

